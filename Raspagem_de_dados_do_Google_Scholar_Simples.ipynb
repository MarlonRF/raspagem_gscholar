{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Raspagem de dados do Google Scholar - Simples.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarlonRF/CPGIF_Colab/blob/master/Raspagem_de_dados_do_Google_Scholar_Simples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc5s8F48YZDW"
      },
      "source": [
        "# 1. Avisos, sugestões de uso\n",
        "\n",
        "* Faça upload de arquivo Excel com nome \"lista de nomes.xlsx\". Atenção ao formato .xlsx. Se realizar o upload de arquivo com outro nome ou extensão, vai ter que alterar o script.\n",
        "\n",
        "* Faça um teste com uma lista pequena, no máximo 5 nomes. \n",
        "\n",
        "* Se a lista de nomes for superior a 50 nomes, recomendo quebrar a lista em várias outras e executar cada uma separadamente. Buscas continuas no Google Scholar, com o mesmo endereço de IP, vão levantar alerta sobre o uso de bots. O seu acesso será bloqueado por uns dias (ainda vai conseguir acessar via Browser, mas com CAPTCHA). Dê um intervalo de 1 hora entre a execução das listas.\n",
        "\n",
        "* O tempo de excecusão pode variar. Quanto maior a lista, maior a variação. O teste com 5 nomes, não levou mais que 5 minutos.\n",
        "\n",
        "* Vou aperfeiçoar o script ao longo do tempo, mas se houver algum bloqueio ou mudanças no Google Scholar, o script pode deixar de funcionar. \n",
        "\n",
        "* Nem todos os nomes serão encontrados pelos mais variados motivos, mesmo que existam no Google Scholar (falso negativo). A dificuldade mais comum serão os casos em que o pesquisador usar um bem diferente no nome utilizado na busca, por exemplo: Cesare Mansueto Giulio Lattes -> César Lattes \n",
        "\n",
        "* Alguns nomes que não fazem parte da lista serão adicionados aos resultados (falso positivo). Próxima versão do script implemento uma solução.\n",
        "\n",
        "* Vou \n",
        "---\n",
        "# 2. Instruções\n",
        "\n",
        "A lista de nome é a mais simples possível. Preferêncialmene nome completo. \n",
        "<img src='https://drive.google.com/uc?id=1kUP8ucC2FcKidYPq6nMJN4rjZabCvpUt'></img>\n",
        "\n",
        "\n",
        "\n",
        "## 2.1 Upload do arquivo Excel\n",
        "\n",
        "Clicar no 4º ícone à esquerda (Arquivos) e depois no 1º icone dos 3 que irão surgir \"Fazer Upload para armaza...\"\n",
        "<img src='https://drive.google.com/uc?id=1sMANy4ZCFue1iSpPP0FrclXAvAMMR6Eo'></img>\n",
        "\n",
        "\n",
        "\n",
        "## 2.2. Executar o script\n",
        "Clique no ícone da célular onde está escrito o script\n",
        "<img src='https://drive.google.com/uc?id=1PxedJ08n7lUgbc3JdjF0hakOjujOeuhE'></img>\n",
        "\n",
        "\n",
        "\n",
        "## 2.3 Download do arquivo.\n",
        " Dados serão salvos no mesmo arquivo, mas em outra planilha. Só baixar\n",
        " <img src='https://drive.google.com/uc?id=1AZWAkYDESKBU1sr1vj4R5HFnBK7aXvDF'></img>\n",
        " \n",
        "\n",
        "\n",
        "\n",
        " Resultado deve esse.\n",
        " <img src='https://drive.google.com/uc?id=1MwPQypO9mR23e85QH62j5_4dXBEGEZ6R'></img>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFpeJ3kV2n2B"
      },
      "source": [
        "# Nova seção"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgeaZHvbUQf0"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "# SCRIPT!\n",
        "É só executar. Se você for bloqueado pelo Google, vai receber mensagem de erro. O jeito é esperar uns dias para ser desbloqueado.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVuHukIdQdit",
        "outputId": "da1c3880-5330-4ddf-9de3-1d21cc5b19fd"
      },
      "source": [
        "\n",
        "# Suprime todo Output dessa celula \n",
        "!pip install scholarly # instala biblioteca no COLAB para execução\n",
        "!pip install scraperapi-sdk\n",
        "\n",
        "# Bibliotecas\n",
        "from scholarly import scholarly, ProxyGenerator # Faz o meio de campo com o BeautfulSoup para obter os dados no GoogleScholar \n",
        "import pandas as pd # Dataframes\n",
        "import numpy as np # Cálculos numéricos\n",
        "from scraper_api import ScraperAPIClient # Alternativa para utilizar outros Proxies \n",
        "import random # Para utilizar aleatórios\n",
        "import pickle # salva dados do Python\n",
        "import matplotlib.pyplot as plt # Gráficos\n",
        "\n",
        "# Funções\n",
        "\n",
        "# Quebra o nome completo e compõe novo nome: 1º e último\n",
        "def quebrarNome(string):\n",
        "  n = string.split()\n",
        "  ultimo = len(n)-1\n",
        "  novo_n = (n[0]+' '+n[ultimo])\n",
        "  return novo_n\n",
        "\n",
        "# usa proxy para variar IP. Google bloqueia bots\n",
        "\n",
        "# busca e verifica a existencia nomes no Google Acadêmico. \n",
        "# Retorna a lista dos nomes encontrados na forma encontrada\n",
        "# Exemplo: Cesare Mansueto Giulio Lattes -> César Lattes\n",
        "\n",
        "# Histograma com linha da média e da mediana\n",
        "def histograma(x, bins=40,label_x='',label_y='',titulo='', subtitulo=''):\n",
        "  \"\"\"Gráfico Histograma\n",
        "  Parameters\n",
        "  ----------\n",
        "  x : dados númericos: série do Pandas, vetor do numpy\n",
        "  xbins: nº de bins\n",
        "  label_x: rótulo o eixo X\n",
        "  label_y: rótulo do eixo y\n",
        "  titulo: Título do histograma\n",
        "  subtitulo: Subtítulo do histograma\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  Imagem :\n",
        "      retorna histograma\n",
        "  \"\"\"\n",
        "  x = x[~np.isnan(x)] # descarta os valores NA\n",
        "  result = plt.hist(x, bins=40, \n",
        "                    color='blue', \n",
        "                    edgecolor='darkblue', \n",
        "                    alpha=0.2)\n",
        "  plt.axvline(x.mean(), # Linha da média\n",
        "              color='darkblue', \n",
        "              linestyle='dashed', \n",
        "              linewidth=1\n",
        "              )\n",
        "  plt.axvline(np.median(x), #linha da mediana\n",
        "              color='darkred', \n",
        "              linestyle='dashed', \n",
        "              linewidth=1\n",
        "              )\n",
        "  min_ylim, max_ylim = plt.ylim() # coleta os limites do eixo Y para definir altura dos textos\n",
        "  plt.text(x.mean()*1.1,\n",
        "            max_ylim*0.9,\n",
        "            'Média: {:.2f}'.format(x.mean()),\n",
        "            color='darkblue'\n",
        "          )\n",
        "  plt.text(np.median(x)*1.1,\n",
        "            max_ylim*0.8, \n",
        "            'Mediana: {:.2f}'.format(np.median(x)),\n",
        "            color='darkred'\n",
        "          )\n",
        "  # Titulo dos gráfico e dos eixos\n",
        "  plt.title(subtitulo)\n",
        "  plt.suptitle(titulo,fontsize=18, y=1)\n",
        "  plt.xlabel(label_x)\n",
        "  plt.ylabel(label_y)\n",
        "  plt.show\n",
        "\n",
        "def buscarNomes(lista):\n",
        "  \"\"\"Itera sob a lista de nomes\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  list : lista de strings\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  dictionary list:  Lista de dicionários com dados retornados\n",
        "  \"\"\"\n",
        "  dados=[] # lista vazia\n",
        "  #Itera sob a lista de nomes\n",
        "  # Cada busca retorna um dicionário com os dados do autor. No fim no loop, teremos um lista de dicionários, facilmente convertido em DataFrame do Pandas\n",
        "  for nome in lista:\n",
        "    busca=next(scholarly.search_author(nome),False) # 1º tenta busca pelo nome completo\n",
        "    if busca  != False:\n",
        "      autor = scholarly.fill(busca,sections=[])\n",
        "      dados.append(autor)\n",
        "      # Caso não encontre pelo nome completo, criamos um \"novo\" nome para o autor com a função quebrarNome: 1º e o último\n",
        "    elif next(scholarly.search_author(quebrarNome(nome)),False) != False:\n",
        "      autor = scholarly.fill(scholarly.fill(next(scholarly.search_author(quebrarNome(nome)),False),sections=[]))\n",
        "      dados.append(autor)\n",
        "    else: \n",
        "      pass\n",
        "  return dados\n",
        "\n",
        "\n",
        "# aplica a função retorna Perfil em uma lista de strings (nomes)\n",
        "def buscarPerfiz(lista):\n",
        "  lista_retorno = []\n",
        "  for nome in lista:\n",
        "      perfil = retornaPerfil(nome)\n",
        "      lista_retorno.append(perfil)\n",
        "  return lista_retorno\n",
        "\n",
        "def buscar_por_excel(tabela,inicial=0,final=0):\n",
        "  tabela = pd.read_excel(tabela)\n",
        "  lista = tabela.Nome\n",
        "  lista = lista[inicial:final]\n",
        "  dados_retorno = buscarNomes(lista)\n",
        "  dados_retorno = [x for x in dados_retorno if x != False] # Remove os retornos False da lista. Sem isso o Pondas não aceita entrada dos dados\n",
        "  return dados_retorno\n",
        "  #print(lista)\n",
        "    \n",
        "def limparBol(df): \n",
        "  return [x for x in df if x != False]\n",
        "    \n",
        "# classe para cria objeto que usa SCRAPERAPI, uma boa ferramenta de proxy\n",
        "class ScraperAPI(ProxyGenerator):\n",
        "  def __init__(self, api_key):\n",
        "      self._api_key = api_key\n",
        "      self._client = ScraperAPIClient(api_key)\n",
        "      assert api_key is not None      \n",
        "      super(ScraperAPI, self).__init__()      \n",
        "      self._TIMEOUT = 120\n",
        "      self._session = self._client\n",
        "      self._session.proxies = {}\n",
        "      \n",
        "  def _new_session(self):\n",
        "      self.got_403 = False\n",
        "      return self._session\n",
        "  \n",
        "  def _close_session(self):\n",
        "      pass  \n",
        "    \n",
        "# planifica dicionário dentro do dataframe\n",
        "def unpack(df, column, fillna=None):\n",
        "  ret = None\n",
        "  if fillna is None:\n",
        "      ret = pd.concat([df, pd.DataFrame((d for idx, d in df[column].iteritems()))], axis=1)\n",
        "      del ret[column]\n",
        "  else:\n",
        "      ret = pd.concat([df, pd.DataFrame((d for idx, d in df[column].iteritems())).fillna(fillna)], axis=1)\n",
        "      del ret[column]\n",
        "  return ret\n",
        "\n",
        "# descarta vetores com info inúteis dentro das informações das publicacões\n",
        "def drop_colunas_pubs(df):\n",
        "  df=df.drop(['container_type','filled','source'], axis = 1)\n",
        "  return df\n",
        "\n",
        "\n",
        "df_nomes=pd.read_excel('lista de nomes.xlsx',header=None)\n",
        "\n",
        "lista_nomes=list(df_nomes[0]) # trasforma a primeira coluna de dados em uma lista\n",
        "\n",
        "resultado=buscarNomes(lista_nomes) # realiza a busca dos nomes e retorna uma lista de dicionários do Python. \n",
        "\n",
        "df=pd.DataFrame(resultado) # Lista de dicionários em dataframe do Pandas \n",
        "df.drop_duplicates(subset =\"scholar_id\", keep = False, inplace = True)  # Remove linhas duplicadas de acordo com scholar_id, que é unívoco\n",
        "\n",
        "df=unpack(df, 'cites_per_year', 0) # \"desempacota o dataframe dentro dessa variável em novas colunas\"\n",
        "df['pubs']=df['publications'].apply(pd.json_normalize) # normaliza os dados dentro da variável publications e cria nova variável\n",
        "df['pubs']=df['pubs'].apply(drop_colunas_pubs) # descarta vetores com info inúteis dentro do vetor 'pubs'\n",
        "df=df.drop(['container_type','filled','source','coauthors','publications'], axis = 1) # descarta vetores com info inúteis\n",
        "# Salva a tabela\n",
        "df.to_excel('lista de nomes.xlsx', sheet_name='Resultado da raspagem', index = False)\n",
        "print('\\n \\n ###############################')\n",
        "print('Script executado com sucesso! \\n Pode baixar a planilha com os dados.')\n",
        "print('\\n \\n ###############################')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scholarly in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: stem in /usr/local/lib/python3.7/dist-packages (from scholarly) (1.8.0)\n",
            "Requirement already satisfied: bibtexparser in /usr/local/lib/python3.7/dist-packages (from scholarly) (1.2.0)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.7/dist-packages (from scholarly) (0.1.11)\n",
            "Requirement already satisfied: requests[security] in /usr/local/lib/python3.7/dist-packages (from scholarly) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from scholarly) (4.6.3)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (from scholarly) (3.141.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from scholarly) (3.7.4.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.7/dist-packages (from scholarly) (0.16.0)\n",
            "Requirement already satisfied: free-proxy in /usr/local/lib/python3.7/dist-packages (from scholarly) (1.0.2)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.7/dist-packages (from scholarly) (0.5.1)\n",
            "Requirement already satisfied: PySocks in /usr/local/lib/python3.7/dist-packages (from scholarly) (1.7.1)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.7/dist-packages (from scholarly) (1.0.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from bibtexparser->scholarly) (2.4.7)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from bibtexparser->scholarly) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[security]->scholarly) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[security]->scholarly) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[security]->scholarly) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[security]->scholarly) (2.10)\n",
            "Requirement already satisfied: cryptography>=1.3.4; extra == \"security\" in /usr/local/lib/python3.7/dist-packages (from requests[security]->scholarly) (3.4.7)\n",
            "Requirement already satisfied: pyOpenSSL>=0.14; extra == \"security\" in /usr/local/lib/python3.7/dist-packages (from requests[security]->scholarly) (20.0.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from free-proxy->scholarly) (4.2.6)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.7/dist-packages (from sphinx-rtd-theme->scholarly) (1.8.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from arrow->scholarly) (2.8.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4; extra == \"security\"->requests[security]->scholarly) (1.14.5)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from pyOpenSSL>=0.14; extra == \"security\"->requests[security]->scholarly) (1.15.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->scholarly) (2.6.1)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->scholarly) (2.9.0)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->scholarly) (0.16)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->scholarly) (1.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->scholarly) (20.9)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->scholarly) (1.2.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->scholarly) (2.11.3)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->scholarly) (2.1.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->scholarly) (0.7.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->scholarly) (54.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4; extra == \"security\"->requests[security]->scholarly) (2.20)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel!=2.0,>=1.3->sphinx->sphinx-rtd-theme->scholarly) (2018.9)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx->sphinx-rtd-theme->scholarly) (1.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->sphinx->sphinx-rtd-theme->scholarly) (1.1.1)\n",
            "Requirement already satisfied: scraperapi-sdk in /usr/local/lib/python3.7/dist-packages (0.2.2)\n",
            "\n",
            " \n",
            " ###############################\n",
            "Script executado com sucesso! \n",
            " Pode baixar a planilha com os dados.\n",
            "\n",
            " \n",
            " ###############################\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}